{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9063dad",
   "metadata": {},
   "source": [
    "# üåç Demo 4: Putting Your Forecast to the Test\n",
    "\n",
    "## üß† Learning Objectives\n",
    "- Use the `weatherbench2` Python library for forecast verification.\n",
    "- Load custom forecast and ERA5 data for comparison.\n",
    "- Compute standard metrics like RMSE and ACC.\n",
    "- Focus evaluation on specific countries or regions.\n",
    "- Visualize how forecast skill changes with lead time.\n",
    "- Understand the power of localized hindcasting for tailored insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d816bc8d",
   "metadata": {},
   "source": [
    "## üéØ Objective\n",
    "\n",
    "In this demo, we scientifically **grade the forecast** you created in **Demo 2**, using professional tools like `weatherbench2`. Instead of relying on generic operational forecast products, we‚Äôll do a **custom local evaluation**.\n",
    "\n",
    "**Theme:** *We are doing this locally to get custom answers that operational websites can't provide.*\n",
    "\n",
    "You‚Äôll compute metrics like RMSE and ACC over custom regions (like Kenya or Chile), visualize model skill, and learn why localized hindcasts are powerful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b95efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import xskillscore as xs  # For verification metrics\n",
    "\n",
    "# Optional: Import warnings to suppress potential warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b39aae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fde1cccc1b47c79f387259ec36fc10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Forecast file:', layout=Layout(width='80%'), placeholder='Enter path to NetCDF for‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecast_path = widgets.Text(\n",
    "    description='Forecast file:',\n",
    "    placeholder='Enter path to NetCDF forecast from Demo 2',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "display(forecast_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a09f0bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90549bf2f5684892a7ff570cc627cc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Load Forecast', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4a2d63f0e3487c828711de5cbf16ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_forecast(path):\n",
    "    try:\n",
    "        forecast_ds = xr.open_dataset(path)\n",
    "        display(Markdown(\"‚úÖ Forecast data loaded successfully.\"))\n",
    "        return forecast_ds\n",
    "    except Exception as e:\n",
    "        display(Markdown(f\"‚ùå Error loading forecast: {e}\"))\n",
    "        return None\n",
    "\n",
    "forecast_ds = None\n",
    "\n",
    "# Button to trigger loading\n",
    "load_button = widgets.Button(description=\"Load Forecast\")\n",
    "load_output = widgets.Output()\n",
    "\n",
    "def on_load_clicked(b):\n",
    "    global forecast_ds\n",
    "    with load_output:\n",
    "        load_output.clear_output()\n",
    "        if not forecast_path.value.strip():\n",
    "            display(Markdown(\"‚ùå Please enter a valid file path.\"))\n",
    "        else:\n",
    "            forecast_ds = load_forecast(forecast_path.value)\n",
    "\n",
    "load_button.on_click(on_load_clicked)\n",
    "display(load_button, load_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbf1cd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "‚úÖ ERA5 ground truth variable `2m_temperature` loaded and time-aligned."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "if forecast_ds is not None:\n",
    "    forecast_time = forecast_ds.time\n",
    "    forecast_var = list(forecast_ds.data_vars)[0]  # e.g., \"2t\"\n",
    "\n",
    "    # Mapping from forecast variable names to ERA5 GCS variable names\n",
    "    var_map = {\n",
    "        \"2t\": \"2m_temperature\",\n",
    "        \"z500\": \"geopotential\",  # adjust if needed\n",
    "        \"u10\": \"10m_u_component_of_wind\",\n",
    "        \"v10\": \"10m_v_component_of_wind\",\n",
    "        # Add more mappings if needed\n",
    "    }\n",
    "\n",
    "    era5_var = var_map.get(forecast_var, forecast_var)\n",
    "\n",
    "    # Load from public Zarr store on GCS\n",
    "    era5_path = \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\"\n",
    "\n",
    "    full_era5 = xr.open_zarr(\n",
    "        era5_path,\n",
    "        chunks=None,\n",
    "        storage_options={\"token\": \"anon\"}\n",
    "    )[[era5_var]]\n",
    "\n",
    "    # Select only the matching forecast times\n",
    "    era5_ds = full_era5.sel(time=forecast_time)\n",
    "\n",
    "    display(Markdown(f\"‚úÖ ERA5 ground truth variable `{era5_var}` loaded and time-aligned.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40b70cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ceac2d2af84494a41a15fecb18b75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Region:', options=('Global', 'Northern Hemisphere', 'Tropics', 'Bangladesh', 'Chile', 'N‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6c5829af094156a4da41bd699fb3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Metrics:', index=(0, 1), options=('rmse', 'acc'), value=('rmse', 'acc'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region_bounds = {\n",
    "    \"Global\": (-90, 90, 0, 360),\n",
    "    \"Northern Hemisphere\": (0, 90, 0, 360),\n",
    "    \"Tropics\": (-30, 30, 0, 360),\n",
    "    \"Bangladesh\": (20.5, 26.5, 88, 92.5),\n",
    "    \"Chile\": (-56, -17, -76, -66),\n",
    "    \"Nigeria\": (4, 14, 3, 15),\n",
    "    \"Ethiopia\": (3, 15, 33, 48),\n",
    "    \"Kenya\": (-5, 5, 33, 42)\n",
    "}\n",
    "\n",
    "region_selector = widgets.Dropdown(\n",
    "    options=region_bounds.keys(),\n",
    "    value=\"Global\",\n",
    "    description=\"Region:\"\n",
    ")\n",
    "\n",
    "metric_selector = widgets.SelectMultiple(\n",
    "    options=[\"rmse\", \"acc\"],  # Supported: rmse, acc (anomaly correlation)\n",
    "    value=[\"rmse\", \"acc\"],\n",
    "    description=\"Metrics:\"\n",
    ")\n",
    "\n",
    "display(region_selector, metric_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6316fbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeb2fb6a9544748a7a466f145900c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run Verification', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be519dec302046b29276641efc259f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Step 5 (FIXED): Spatial Subsetting with Flexible Coordinate Names\n",
    "# -------------------------------\n",
    "\n",
    "def standardize_spatial_dims(ds):\n",
    "    \"\"\"Rename lat/lon dimensions to 'latitude' and 'longitude' if needed.\"\"\"\n",
    "    ds = ds.copy()\n",
    "    # Mapping common names\n",
    "    lat_names = ['latitude', 'lat', 'g0_lat_1', 'y']\n",
    "    lon_names = ['longitude', 'lon', 'g0_lon_2', 'x']\n",
    "\n",
    "    lat_dim = None\n",
    "    for name in lat_names:\n",
    "        if name in ds.dims:\n",
    "            lat_dim = name\n",
    "            break\n",
    "\n",
    "    lon_dim = None\n",
    "    for name in lon_names:\n",
    "        if name in ds.dims:\n",
    "            lon_dim = name\n",
    "            break\n",
    "\n",
    "    if lat_dim is None or lon_dim is None:\n",
    "        raise ValueError(f\"Could not find latitude/longitude in dataset dimensions: {list(ds.dims)}\")\n",
    "\n",
    "    # Rename to standard names\n",
    "    ds = ds.rename({lat_dim: 'latitude', lon_dim: 'longitude'})\n",
    "\n",
    "    # Also standardize coordinate variables\n",
    "    if 'latitude' in ds.coords:\n",
    "        pass\n",
    "    elif 'latitude' in ds.variables:  # sometimes stored as variable\n",
    "        ds = ds.assign_coords(latitude=ds['latitude'])\n",
    "    else:\n",
    "        raise ValueError(\"Latitude coordinate not found.\")\n",
    "\n",
    "    if 'longitude' in ds.coords:\n",
    "        pass\n",
    "    elif 'longitude' in ds.variables:\n",
    "        ds = ds.assign_coords(longitude=ds['longitude'])\n",
    "    else:\n",
    "        raise ValueError(\"Longitude coordinate not found.\")\n",
    "\n",
    "    # Ensure longitude is in 0-360 format for consistency with ERA5\n",
    "    # Convert from -180-180 to 0-360 if needed\n",
    "    if ds['longitude'].min() < 0:\n",
    "        ds = ds.assign_coords(longitude=((ds['longitude'] + 180) % 360 - 180))\n",
    "        # Then wrap to 0-360\n",
    "        ds = ds.assign_coords(longitude=(ds['longitude'] % 360))\n",
    "        # Sort by longitude because wrapping may unsort\n",
    "        ds = ds.sortby('longitude')\n",
    "\n",
    "    return ds\n",
    "\n",
    "def subset_region(ds, region_key):\n",
    "    ds = standardize_spatial_dims(ds)  # Ensure consistent names\n",
    "    bounds = region_bounds[region_key]\n",
    "    \n",
    "    if isinstance(bounds, str) and bounds == \"land\":\n",
    "        raise NotImplementedError(\"Land mask not implemented here. Skipping.\")\n",
    "    \n",
    "    south, north, west, east = bounds\n",
    "\n",
    "    # Make sure longitudes are in 0‚Äì360 to match ERA5\n",
    "    west = west % 360\n",
    "    east = east % 360\n",
    "\n",
    "    # Handle crossing the prime meridian\n",
    "    if west <= east:\n",
    "        longitude_slice = slice(west, east)\n",
    "    else:\n",
    "        # Crosses 0¬∞ meridian (e.g., 350 to 10)\n",
    "        ds1 = ds.sel(longitude=slice(west, 360))\n",
    "        ds2 = ds.sel(longitude=slice(0, east))\n",
    "        return xr.concat([ds1, ds2], dim='longitude')\n",
    "\n",
    "    try:\n",
    "        subset = ds.sel(\n",
    "            latitude=slice(north, south),   # latitude usually descends from 90 to -90\n",
    "            longitude=longitude_slice\n",
    "        )\n",
    "        return subset\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error during spatial selection: {e}\")\n",
    "run_button = widgets.Button(description=\"Run Verification\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def run_verification(forecast, truth, region, metrics):\n",
    "    results = xr.Dataset()\n",
    "\n",
    "    # Get variable name\n",
    "    var_name = list(forecast.data_vars)[0]\n",
    "    era5_var = var_map.get(var_name, var_name)\n",
    "    \n",
    "    # Subset both datasets\n",
    "    fc_sub = subset_region(forecast, region)\n",
    "    tr_sub = subset_region(truth, region)\n",
    "\n",
    "    # Align time (just in case)\n",
    "    fc_sub, tr_sub = xr.align(fc_sub, tr_sub, join=\"inner\")\n",
    "\n",
    "    # Extract data\n",
    "    fc_var = fc_sub[var_name]\n",
    "    tr_var = tr_sub[era5_var]\n",
    "\n",
    "    # Lead dimension: assume forecast has 'step' or 'lead_time', or use 'time'\n",
    "    if 'step' in fc_var.dims:\n",
    "        lead_dim = 'step'\n",
    "        lags = fc_var[lead_dim]\n",
    "    else:\n",
    "        lead_dim = 'time'  # fallback\n",
    "        lags = fc_var[lead_dim]  # not ideal, but works for single-step\n",
    "\n",
    "    # Compute metrics over space, reduce to lead time\n",
    "    if \"rmse\" in metrics:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            rmse = xs.rmse(fc_var, tr_var, dim=['latitude', 'longitude'], skipna=True)\n",
    "            results['rmse'] = rmse\n",
    "\n",
    "    if \"acc\" in metrics:\n",
    "        # ACC requires climatology; use global mean over time as reference?\n",
    "        # Here we compute anomaly correlation coefficient\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            acc = xs.pearson_r(\n",
    "                fc_var - fc_var.mean(dim=['latitude', 'longitude']),\n",
    "                tr_var - tr_var.mean(dim=['latitude', 'longitude']),\n",
    "                dim=['latitude', 'longitude']\n",
    "            )\n",
    "            results['acc'] = acc\n",
    "\n",
    "    return results\n",
    "\n",
    "def plot_results(result):\n",
    "    for metric in result.data_vars:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        var = result[metric]\n",
    "        lead_dim = var.dims[0]  # Assume first dim is lead time\n",
    "\n",
    "        var.plot(marker='o')\n",
    "        plt.title(f\"{metric.upper()} vs Forecast Lead Time\")\n",
    "        plt.xlabel(\"Lead Time\")\n",
    "        plt.ylabel(metric.upper())\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def on_run_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if forecast_ds is None or era5_ds is None:\n",
    "            display(Markdown(\"‚ùå Please load both forecast and ERA5 data first.\"))\n",
    "            return\n",
    "        display(Markdown(\"‚è≥ Running verification...\"))\n",
    "        try:\n",
    "            result = run_verification(\n",
    "                forecast_ds,\n",
    "                era5_ds,\n",
    "                region_selector.value,\n",
    "                list(metric_selector.value)\n",
    "            )\n",
    "            display(Markdown(\"‚úÖ Verification complete.\"))\n",
    "            plot_results(result)\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"‚ùå Error during verification: {e}\"))\n",
    "\n",
    "run_button.on_click(on_run_clicked)\n",
    "display(run_button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0cb36",
   "metadata": {},
   "source": [
    "## üìä Interpret Your Results\n",
    "\n",
    "- **Look at the RMSE plot**: How does the error change as the forecast lead time increases? Why is this expected?\n",
    "- **Try changing the region** from \"Global\" to \"Kenya\" and re-run the analysis.\n",
    "    - Does the model's **ACC score** degrade faster or slower in Kenya?\n",
    "    - What does this imply about model performance for **East African** weather?\n",
    "\n",
    "Play with different regions and metrics to gain insights!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d0128",
   "metadata": {},
   "source": [
    "## üîç Key Takeaways\n",
    "\n",
    "- Large operational centers provide broad forecasts ‚Äî but can't offer **custom regional analysis**.\n",
    "- By running a **local hindcast** and benchmarking it with tools like `weatherbench2`, you can answer **targeted, high-impact questions**:\n",
    "    - *How accurate is this model over Bangladesh during monsoon?*\n",
    "    - *How reliable is the 5-day forecast for heatwaves in Chile?*\n",
    "- This is the true power of open science and AI: **empowering local experts** to run meaningful evaluations for their region.\n",
    "\n",
    "üß™ Keep exploring. Try different models, dates, and regions!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
